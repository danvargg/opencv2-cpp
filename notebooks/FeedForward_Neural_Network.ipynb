{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_sNXafaD9M7P"
   },
   "source": [
    "# <font style=\"color:rgb(50,120,229)\">Image Classification using Feed Forward Neural Network</font> \n",
    "In this notebook, we will use a simple feed forward neural network to peform image classification. \n",
    "\n",
    "Traditionally, the \"hello world\" example in image classification used to be a dataset called MNIST which stood for **Modified National Institute of Standards and Technology** database. It was a dataset of 60,000 training images and 10,000 testing images of hand written characters. The size of the images in the dataset was 28x28.  \n",
    "\n",
    "With modern methods, it is very easy to achieve high accuracy on the MNIST dataset. \n",
    "\n",
    "Therefore, in this notebook, we have chosen to use the **Fashion MNIST** dataset which also consists of 28x28 images, but they are derived from fashion items. Like MNIST, the training set consists of 60,000 images and the test set consists of 10,000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "anDcnM9J9M7S"
   },
   "source": [
    "# <font style=\"color:rgb(50,120,229)\">The Problem</font>\n",
    "\n",
    "The figure below shows some samples from the Fashion MNIST dataset.\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/m0alzz7m9c6t88u/fashion-mnist-sprite.png?dl=1\" width=\"600\">\n",
    "\n",
    "There are 10 classes. Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n",
    "\n",
    "\n",
    "We want to perform image classification on this dataset using a feedforward neural network. The task is to train a machine learning algorithm to recognize a new sample from the test set correctly.\n",
    "Here we use libtorch(https://pytorch.org/tutorials/advanced/cpp_frontend.html) for Image classification using feed forward neural network in C++. \n",
    "\n",
    "# <font style = \"color:rgb(8,133,37)\">Import Libraries</font>¶\n",
    "\n",
    "Import required libraries and define constants like\n",
    "- batchSize\n",
    "- epochs\n",
    "- logInterval\n",
    "- Images path of train and test\n",
    "- Labels path of train and test\n",
    "- Torch device(To use CPU  or GPU accordingly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3SGBbF1E9M7T"
   },
   "source": [
    "```cpp\n",
    "#include <stdint.h>\n",
    "#include <torch/torch.h>\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "#include <opencv2/core/core.hpp>\n",
    "#include <opencv2/opencv.hpp>\n",
    "#include <opencv2/highgui/highgui.hpp>\n",
    "#include \"read-mnist.h\"\n",
    "\n",
    "struct Options {\n",
    "  int batchSize = 100; //Batch size\n",
    "  size_t epochs = 20; // Number of epochs\n",
    "  size_t logInterval = 20;\n",
    "  std::ofstream loss_acc_train;\n",
    "  std::ofstream loss_acc_test;\n",
    "  //Paths to train and test images and labels\n",
    "  const char* train_images_path = \"train-images-idx3-ubyte\";\n",
    "  const char* train_labels_path = \"train-labels-idx1-ubyte\";\n",
    "  const char* test_images_path = \"t10k-images-idx3-ubyte\";\n",
    "  const char* test_labels_path = \"t10k-labels-idx1-ubyte\";\n",
    "  torch::DeviceType device = torch::kCPU;\n",
    "};\n",
    "\n",
    "static Options options;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mZPs1iF9M7U"
   },
   "source": [
    "# <font style=\"color:rgb(50,120,229)\">1. The Model</font>\n",
    "\n",
    "We will use raw pixel values as input to the network. The images are simply matrices of size 28x28. So, we reshape the image matrix to an array of size 784 ( 28*28 ) and feed this array to the network. \n",
    "\n",
    "We will use a network with 2 hidden layers having 512 neurons each. \n",
    "\n",
    "The output layer will have 10 layers for the 10 fashion items. The schematic diagram is shown below:\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2017/10/mlp-mnist-schematic.jpg\" width=\"700\">\n",
    "\n",
    "We use libtorch functional module(torch::nn::Module) to define the feed forward network shown above.\n",
    "\n",
    "- **Dense Layer** \n",
    "    \n",
    "        torch::nn::Linear(input_size, output_size)\n",
    "\n",
    "All the defined layers are to be registered explicitly. Then we use forward pass through each layer and apply activation \"relu\" and finally apply log softmax on the output to get probabilities of all the target classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0ZmNglU9M7V"
   },
   "source": [
    "```cpp\n",
    "//Feed Forward network\n",
    "struct Net: torch::nn::Module {\n",
    "    Net() {\n",
    "        fc1 = register_module(\"fc1\", torch::nn::Linear(28*28, 512));\n",
    "        fc2 = register_module(\"fc2\", torch::nn::Linear(512, 512));\n",
    "        fc3 = register_module(\"fc3\", torch::nn::Linear(512, 10));\n",
    "    }\n",
    "\n",
    "    // Implement Forward Pass Algorithm\n",
    "    torch::Tensor forward(torch::Tensor x) {\n",
    "        x = x.view({options.batchSize, -1});\n",
    "        //Input -> Linear -> Relu -> Linear -> Relu -> Linear -> Softmax Classifier-> Output\n",
    "        x = torch::relu(fc1->forward(x));\n",
    "        x = torch::relu(fc2->forward(x));\n",
    "        x = fc3->forward(x);\n",
    "        return torch::log_softmax(x, 1);\n",
    "    }\n",
    "\n",
    "    //Initilaize the constructor with null pointer. More details given in the reference\n",
    "    torch::nn::Linear fc1{nullptr}, fc2{nullptr}, fc3{nullptr};\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UPEzVk3B9M7X"
   },
   "source": [
    "# <font style=\"color:rgb(50,120,229)\">2. Load the Data</font>\n",
    "In libtorch, Fashion MNIST is not a built-in dataset so we need to custom load the data. This dataset is available in ubyte(eg:train-images-idx3-ubyte) format files. This format files are explained here - http://yann.lecun.com/exdb/mnist/.\n",
    "\n",
    "We have 2 different files for images and labels in case of both train and test data. We will use Custom Dataset Class like we did for linear regression earlier to process the data and convert to tensor form. Normalization of images is also performed in read-mnist.h after tensor conversion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDiToNUI9M7Z"
   },
   "source": [
    "```cpp\n",
    "/*Read images from ubyte format and convert to tensors*/\n",
    "torch::Tensor process_images(const std::string& root, bool train) {\n",
    "  const auto path = root + (train ? options.train_images_path: options.test_images_path); //images_path\n",
    "  auto images = read_mnist_images(path); //refer to read-mnist.h\n",
    "\n",
    "  return images;\n",
    "}\n",
    "\n",
    "/*Read labels from ubyte format and convert to tensors*/\n",
    "torch::Tensor process_labels(const std::string& root, bool train) {\n",
    "  const auto path = root + (train ? options.train_labels_path: options.test_labels_path); //labels_path\n",
    "  auto labels = read_mnist_labels(path);//refer to read-mnist.h\n",
    "\n",
    "  return labels;\n",
    "}\n",
    "\n",
    "\n",
    "/*Use CustomDataset class to load any type of dataset other than inbuilt datasets*/\n",
    "class CustomDataset : public torch::data::datasets::Dataset<CustomDataset> {\n",
    "    private:\n",
    "        /* data */\n",
    "        // Should be 2 tensors\n",
    "        torch::Tensor images, labels;\n",
    "        size_t img_size;\n",
    "    public:\n",
    "        CustomDataset(const std::string& root, bool train) {\n",
    "            images = process_images(root, train);\n",
    "            labels = process_labels(root, train);\n",
    "            img_size = images.size(0);\n",
    "        }\n",
    "    \n",
    "        /*Returns the data sample at the given `index*/\n",
    "        torch::data::Example<> get(size_t index) override {\n",
    "            /* This should return {torch::Tensor, torch::Tensor} */\n",
    "            torch::Tensor img = images[index];\n",
    "            torch::Tensor label = labels[index];\n",
    "            return {img.clone(), label.clone()};\n",
    "        };\n",
    "    \n",
    "    torch::optional<size_t> size() const override {\n",
    "        return img_size;\n",
    "    };\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iVH_m6z9M7b"
   },
   "source": [
    "# <font style=\"color:rgb(50,120,229)\">3. Train the Network</font>\n",
    "Training data is passed in set of batches and **negative log likelihood** loss function is used to calculate the loss. Then the loss function is passed through **stochastic gradient descent** optimizer with learning rate 0.01 which is defined in the main().\n",
    "\n",
    "Following are the major functions of training the network\n",
    "- Initialize the network in training mode\n",
    "    \n",
    "        network->train()\n",
    "- Uses negative log likelihood loss\n",
    "        \n",
    "        torch::nll_loss(output, targets)\n",
    "- Computes the gradients in the network\n",
    "        \n",
    "        loss.backward()\n",
    "- Updates the parameters of the network using the computed gradients\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1n1-0_H9M7c"
   },
   "source": [
    "```cpp\n",
    "template <typename DataLoader>\n",
    "void train(std::shared_ptr<Net> network, DataLoader& loader, torch::optim::Optimizer& optimizer, size_t epoch, size_t data_size) {\n",
    "  size_t index = 0;\n",
    "  /*Set network in the training mode*/\n",
    "  network->train();\n",
    "  float Loss = 0, Acc = 0;\n",
    "\n",
    "  for (auto& batch : loader) {\n",
    "    auto data = batch.data.to(options.device);\n",
    "    auto targets = batch.target.to(options.device).view({-1});\n",
    "    // Execute the model on the input data\n",
    "    auto output = network->forward(data);\n",
    "\n",
    "    //Using mean square error loss function to compute loss\n",
    "    auto loss = torch::nll_loss(output, targets);\n",
    "    auto acc = output.argmax(1).eq(targets).sum();\n",
    "\n",
    "    // Reset gradients\n",
    "    optimizer.zero_grad();\n",
    "    // Compute gradients\n",
    "    loss.backward();\n",
    "    //Update the parameters\n",
    "    optimizer.step();\n",
    "\n",
    "    Loss += loss.template item<float>();\n",
    "    Acc += acc.template item<float>();\n",
    "  }\n",
    "\n",
    "  if (index++ % options.log_interval == 0) {\n",
    "  \t  auto end = data_size;\n",
    "\n",
    "      std::cout << \"Train Epoch: \" << epoch << \" \" << end << \"/\" << data_size\n",
    "                << \"\\tLoss: \" << Loss/end << \"\\tAcc: \" << Acc / end\n",
    "                << std::endl;\n",
    "    }\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Kuy5xpK9M7e"
   },
   "source": [
    "# <font style=\"color:rgb(50,120,229)\">4. Test the Model</font>\n",
    "Similar to the above, the test data is passed through the trained network. Loss is calculated on test data at each epoch. After all epochs, 3 sample outputs and their ground truth are displayed.\n",
    "\n",
    "Following are the major functions of test the network\n",
    "- Initialize the network in testing mode\n",
    "        \n",
    "         network->eval()\n",
    "- Compute negative log likelihood loss\n",
    "        \n",
    "         torch::nll_loss(output, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KNqjIVM49M7f"
   },
   "source": [
    "```cpp\n",
    "template <typename DataLoader>\n",
    "void test(std::shared_ptr<Net> network, DataLoader& loader, size_t epoch, size_t data_size) {\n",
    "  network->eval();\n",
    "  size_t index = 0;\n",
    "  float Loss = 0, Acc = 0;\n",
    "  int display_count = 0;\n",
    "\n",
    "  for (const auto& batch : loader) {\n",
    "    auto data = batch.data.to(options.device);\n",
    "    auto targets = batch.target.to(options.device).view({-1});\n",
    "\n",
    "    auto output = network->forward(data);\n",
    "\n",
    "    //To display 3 test image and its output\n",
    "    if (display_count < 3 && epoch == options.epochs) {\n",
    "      cv::Mat test_image(28,28,CV_8UC1);\n",
    "      torch::Tensor tensor = data[display_count].mul_(255).clamp(0,255).to(torch::kU8);\n",
    "      tensor = tensor.to(torch::kCPU);\n",
    "      std::memcpy((void*)test_image.data,tensor.data_ptr(),sizeof(torch::kU8)*tensor.numel());\n",
    "\n",
    "      std::cout << \"***** TESTING on TEST IMAGE \" << display_count << \" *****\" << std::endl;\n",
    "      std::cout << \"GroundTruth: \" << targets[display_count].template item<float>()\n",
    "                << \", Prediction: \" << output[display_count].argmax() << std::endl;\n",
    "      std::cout << \"Output Probabilities\" << std::endl;\n",
    "      for (int i =0; i < output[display_count].size(0); i++) {\n",
    "        std::cout << \"Class: \" << i << \" \" << torch::exp(output[display_count])[i].template item<float>()  << std::endl;\n",
    "      }\n",
    "      cv::imwrite(\"OUTPUT_GT_\" + std::to_string(targets[display_count].template item<int>()) +\n",
    "                  \"_Pred_\" + std::to_string(output[display_count].argmax().template item<int>()) + \".jpg\", test_image);\n",
    "      std::cout << \"Outputs saved, Please checkout the output images\" << std::endl;\n",
    "\n",
    "      display_count++;\n",
    "    }\n",
    "\n",
    "    auto loss = torch::nll_loss(output, targets);\n",
    "    auto acc = output.argmax(1).eq(targets).sum();\n",
    "\n",
    "    Loss += loss.template item<float>();\n",
    "    Acc += acc.template item<float>();\n",
    "  }\n",
    "\n",
    "  if (index++ % options.logInterval == 0) {\n",
    "    options.loss_acc_test << std::to_string(Loss/data_size) + \",\" + std::to_string(Acc/data_size) << std::endl;\n",
    "    std::cout << \"Val Epoch: \" << epoch\n",
    "              << \"\\tVal Loss: \" << Loss / data_size << \"\\tVal ACC:\"<< Acc / data_size << std::endl;\n",
    "  }\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hftPnO8S9M7h"
   },
   "source": [
    "# <font style=\"color:rgb(50,120,229)\">5. Main function</font>\n",
    "Main function contains following steps:\n",
    "- **Data Processing**\n",
    "    - Data is processed within Custom Dataset Constructer and converted to tensors. Here, we already have separate\n",
    "      train and test data.\n",
    "          auto dataset = torch::data::datasets::MNIST(\"./mnist\")\n",
    "            .map(torch::data::transforms::Normalize<>(0.5, 0.5))\n",
    "            .map(torch::data::transforms::Stack<>());\n",
    "- **Data Loader**\n",
    "    - This provides options for batch size, number of workers to be used to speed up the data loading.\n",
    "            auto data_loader = torch::data::make_data_loader(\n",
    "                std::move(dataset),\n",
    "                torch::data::DataLoaderOptions().batch_size(kBatchSize).workers(2));\n",
    "- **Model Initialization**\n",
    "    - Define network parameters\n",
    "            struct Net : torch::nn::Module {};\n",
    "                void a(std::shared_ptr<Net> net) { }\n",
    "                int main() {\n",
    "                  auto net = std::make_shared<Net>();\n",
    "                  a(net);\n",
    "                }\n",
    "- **Training**\n",
    "    - Define the optimizer and call the train function epoch number of times and observe the loss values.\n",
    "            torch::optim::Adam generator_optimizer(\n",
    "            generator->parameters(), torch::optim::AdamOptions(2e-4).beta1(0.5));\n",
    "            train(net, *train_loader, generator_optimizer, epoch_number, train_dataset_size);\n",
    "- **Testing**\n",
    "    - Call the test function in each epoch and observe the loss values.\n",
    "            test(net, *test_loader, test_dataset_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-bvqpV49M7h"
   },
   "source": [
    "```cpp\n",
    "int main() {\n",
    "    /*Path to Fashion Mnist*/\n",
    "    std::string root_string = \"./fashion-mnist/\";\n",
    "    bool isTrain = true; //Flag to create train or test data\n",
    "\n",
    "    /*Uses Custom Dataset Class to load train data. Apply stack collation which takes \n",
    "      batch of tensors and stacks them into single tensor along the first dimension*/\n",
    "    auto train_dataset = CustomDataset(root_string, isTrain).map(torch::data::transforms::Stack<>());\n",
    "    /*Data Loader provides options to speed up the data loading like batch size, number of workers*/\n",
    "    auto train_loader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(\n",
    "        std::move(train_dataset), options.batch_size);\n",
    "    auto train_size = train_dataset.size().value();\n",
    "\n",
    "    /*Process and load test dat similar to above*/\n",
    "    auto test_dataset = CustomDataset(root_string, false).map(torch::data::transforms::Stack<>());\n",
    "    auto test_loader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(\n",
    "        std::move(test_dataset), options.batch_size);\n",
    "    auto test_size = test_dataset.size().value();\n",
    "\n",
    "    /*Create Feed forward network*/\n",
    "    auto net = std::make_shared<Net>();\n",
    "    // torch::load(net, \"net.pt\"); /*To use trained model*/\n",
    "\n",
    "    /*Using stochastic gradient descent optimizer with learning rate 0.01*/\n",
    "    torch::optim::SGD optimizer(net->parameters(), 0.01); // Learning Rate 0.01\n",
    "\n",
    "    for (size_t i = 0; i < options.iterations; i++) {\n",
    "        /*Run the training for all iterations*/\n",
    "        train(net, *train_loader, optimizer, i + 1, train_size);\n",
    "        std::cout << std::endl;\n",
    "        /*Run on the validation set for all iterations*/\n",
    "        test(net, *test_loader, i+1, test_size);\n",
    "        /*Save the network*/\n",
    "        torch::save(net, \"net.pt\");\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Epz79QLY9M7i"
   },
   "source": [
    "# <font style=\"color:rgb(50,120,229)\">6. Run inference on saved model</font>\n",
    "We load the saved network to run inference on test data. Initialize the network and then use\n",
    "        \n",
    "       torch::load(network, path_to_network)\n",
    "to load the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JX3viB919M7j"
   },
   "source": [
    "```cpp\n",
    "int main() {\n",
    "    /*Path to Fashion Mnist*/\n",
    "    std::string root_string = \"./fashion-mnist/\";\n",
    "\n",
    "    /*Process and load test dat similar to above*/\n",
    "    auto test_dataset = CustomDataset(root_string, false).map(torch::data::transforms::Stack<>());\n",
    "    auto test_loader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(\n",
    "        std::move(test_dataset), options.batch_size);\n",
    "    auto test_size = test_dataset.size().value();\n",
    "\n",
    "    auto net = std::make_shared<Net>();\n",
    "    torch::load(net, \"net.pt\");\n",
    "    test(net, *test_loader, options.epochs, test_size);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ko3bEkRL9M7k"
   },
   "source": [
    "# <font style=\"color:blue\">Steps to Compile and Run the Code on Google Colab</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ake-gOIq9M7m"
   },
   "source": [
    "## <font style=\"color:green\">Download LibTorch</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "g16kAVKK9M7o",
    "outputId": "ee22945f-2a78-4c5b-f0e9-2f16d971f7e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-04 19:08:24--  https://download.pytorch.org/libtorch/cu101/libtorch-shared-with-deps-1.3.1.zip\n",
      "Resolving download.pytorch.org (download.pytorch.org)... 13.35.7.126, 13.35.7.106, 13.35.7.18, ...\n",
      "Connecting to download.pytorch.org (download.pytorch.org)|13.35.7.126|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 740942259 (707M) [application/zip]\n",
      "Saving to: ‘libtorch.zip’\n",
      "\n",
      "libtorch.zip        100%[===================>] 706.62M   112MB/s    in 6.6s    \n",
      "\n",
      "2020-01-04 19:08:32 (107 MB/s) - ‘libtorch.zip’ saved [740942259/740942259]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://download.pytorch.org/libtorch/cu101/libtorch-shared-with-deps-1.3.1.zip -O libtorch.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NSuBxcvI9M7s",
    "outputId": "071a1038-eb09-4774-9652-bae980a3ea5a"
   },
   "outputs": [],
   "source": [
    "!unzip libtorch.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "re_ku3jR9M7w"
   },
   "outputs": [],
   "source": [
    "!rm -r libtorch.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULTB7Kxq9M70"
   },
   "source": [
    "## <font style=\"color:green\">Download Code</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "vish_NdE9M71",
    "outputId": "a86c765b-909e-428d-f44c-d65f30b25275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-04 19:08:55--  https://www.dropbox.com/s/cf0yvfzxml1x8v2/feed-forward.zip?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/cf0yvfzxml1x8v2/feed-forward.zip [following]\n",
      "--2020-01-04 19:08:55--  https://www.dropbox.com/s/dl/cf0yvfzxml1x8v2/feed-forward.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uce45bf2110b9aeaa6bb997b0c8d.dl.dropboxusercontent.com/cd/0/get/AvjLzW_rovLfl9VeFzR39M66Jr7bn2u6aVBF7O54RrJFT8lQUwze5U6bgNBVPz6dabkh-b6nRLDH1cc5XZIUkdRu3Ae9OiF86i6d5dDldGijlMWwKv29ofL68tJSc2b0zuM/file?dl=1# [following]\n",
      "--2020-01-04 19:08:56--  https://uce45bf2110b9aeaa6bb997b0c8d.dl.dropboxusercontent.com/cd/0/get/AvjLzW_rovLfl9VeFzR39M66Jr7bn2u6aVBF7O54RrJFT8lQUwze5U6bgNBVPz6dabkh-b6nRLDH1cc5XZIUkdRu3Ae9OiF86i6d5dDldGijlMWwKv29ofL68tJSc2b0zuM/file?dl=1\n",
      "Resolving uce45bf2110b9aeaa6bb997b0c8d.dl.dropboxusercontent.com (uce45bf2110b9aeaa6bb997b0c8d.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
      "Connecting to uce45bf2110b9aeaa6bb997b0c8d.dl.dropboxusercontent.com (uce45bf2110b9aeaa6bb997b0c8d.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30884038 (29M) [application/binary]\n",
      "Saving to: ‘feed-forward.zip’\n",
      "\n",
      "feed-forward.zip    100%[===================>]  29.45M  3.66MB/s    in 8.0s    \n",
      "\n",
      "2020-01-04 19:09:04 (3.70 MB/s) - ‘feed-forward.zip’ saved [30884038/30884038]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://www.dropbox.com/s/cf0yvfzxml1x8v2/feed-forward.zip?dl=1\" -O feed-forward.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "DZnO_FDC9M74",
    "outputId": "386386a4-ebf0-42c4-e3da-dfac97f69828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  feed-forward.zip\n",
      "   creating: feed-forward/\n",
      "  inflating: feed-forward/CMakeLists.txt  \n",
      "   creating: feed-forward/fashion-mnist/\n",
      "  inflating: feed-forward/fashion-mnist/t10k-images-idx3-ubyte  \n",
      "  inflating: feed-forward/fashion-mnist/t10k-labels-idx1-ubyte  \n",
      "  inflating: feed-forward/fashion-mnist/train-images-idx3-ubyte  \n",
      "  inflating: feed-forward/fashion-mnist/train-labels-idx1-ubyte  \n",
      "  inflating: feed-forward/feedforward.cpp  \n",
      "  inflating: feed-forward/read-mnist.h  \n"
     ]
    }
   ],
   "source": [
    "!unzip feed-forward.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcpKPkMU9M77"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"feed-forward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eMI7ZCnZ9M79"
   },
   "source": [
    "## <font style=\"color:green\">Compile</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "sZ5c6U_M9M7-",
    "outputId": "149f48e1-3407-4d45-c5fa-a649e8cb1d2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 7.4.0\n",
      "-- The CXX compiler identification is GNU 7.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Looking for pthread_create\n",
      "-- Looking for pthread_create - not found\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Found CUDA: /usr/local/cuda (found version \"10.0\") \n",
      "-- Caffe2: CUDA detected: 10.0\n",
      "-- Caffe2: CUDA nvcc is: /usr/local/cuda/bin/nvcc\n",
      "-- Caffe2: CUDA toolkit directory: /usr/local/cuda\n",
      "-- Caffe2: Header version is: 10.0\n",
      "-- Found CUDNN: /usr/lib/x86_64-linux-gnu/libcudnn.so  \n",
      "-- Found cuDNN: v7.6.5  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libcudnn.so)\n",
      "-- Autodetected CUDA architecture(s):  6.0\n",
      "-- Added CUDA NVCC flags for: -gencode;arch=compute_60,code=sm_60\n",
      "-- Found torch: /content/libtorch/lib/libtorch.so  \n",
      "-- Found OpenCV: /usr (found version \"3.2.0\") \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /content/feed-forward\n"
     ]
    }
   ],
   "source": [
    "!cmake -DCMAKE_PREFIX_PATH=$PWD/../libtorch ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ZTfc04gF9M8D",
    "outputId": "54f979de-4c76-4688-ced1-db011344c9de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mScanning dependencies of target ffnet\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/ffnet.dir/feedforward.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable ffnet\u001b[0m\n",
      "[100%] Built target ffnet\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sNvmn0bO9M8I"
   },
   "source": [
    "## <font style=\"color:green\">Run </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IyfNIOoo9M8K",
    "outputId": "21298e7b-a7dc-4c88-86ee-dfcc71993790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: CUDA\n",
      "Train Epoch: 1 60000/60000\tLoss: 0.0155684\tAcc: 0.52135\n",
      "\n",
      "Val Epoch: 1\tVal Loss: 0.00953094\tVal ACC:0.6615\n",
      "Train Epoch: 2 60000/60000\tLoss: 0.00795719\tAcc: 0.7168\n",
      "\n",
      "Val Epoch: 2\tVal Loss: 0.00726852\tVal ACC:0.7348\n",
      "Train Epoch: 3 60000/60000\tLoss: 0.00655906\tAcc: 0.772033\n",
      "\n",
      "Val Epoch: 3\tVal Loss: 0.00630846\tVal ACC:0.7793\n",
      "Train Epoch: 4 60000/60000\tLoss: 0.00584037\tAcc: 0.799617\n",
      "\n",
      "Val Epoch: 4\tVal Loss: 0.00579063\tVal ACC:0.7979\n",
      "Train Epoch: 5 60000/60000\tLoss: 0.00539863\tAcc: 0.814033\n",
      "\n",
      "Val Epoch: 5\tVal Loss: 0.00549065\tVal ACC:0.8085\n",
      "Train Epoch: 6 60000/60000\tLoss: 0.00510948\tAcc: 0.823933\n",
      "\n",
      "Val Epoch: 6\tVal Loss: 0.0052703\tVal ACC:0.8147\n",
      "Train Epoch: 7 60000/60000\tLoss: 0.00489814\tAcc: 0.83015\n",
      "\n",
      "Val Epoch: 7\tVal Loss: 0.00510668\tVal ACC:0.8192\n",
      "Train Epoch: 8 60000/60000\tLoss: 0.00474306\tAcc: 0.834617\n",
      "\n",
      "Val Epoch: 8\tVal Loss: 0.00497094\tVal ACC:0.8232\n",
      "Train Epoch: 9 60000/60000\tLoss: 0.00461981\tAcc: 0.8378\n",
      "\n",
      "Val Epoch: 9\tVal Loss: 0.00484384\tVal ACC:0.8284\n",
      "Train Epoch: 10 60000/60000\tLoss: 0.0045123\tAcc: 0.842333\n",
      "\n",
      "Val Epoch: 10\tVal Loss: 0.00471928\tVal ACC:0.8332\n",
      "Train Epoch: 11 60000/60000\tLoss: 0.00443534\tAcc: 0.844567\n",
      "\n",
      "Val Epoch: 11\tVal Loss: 0.0047282\tVal ACC:0.8308\n",
      "Train Epoch: 12 60000/60000\tLoss: 0.00434924\tAcc: 0.848217\n",
      "\n",
      "Val Epoch: 12\tVal Loss: 0.00463708\tVal ACC:0.8314\n",
      "Train Epoch: 13 60000/60000\tLoss: 0.00427386\tAcc: 0.850817\n",
      "\n",
      "Val Epoch: 13\tVal Loss: 0.00456394\tVal ACC:0.8374\n",
      "Train Epoch: 14 60000/60000\tLoss: 0.00421106\tAcc: 0.8533\n",
      "\n",
      "Val Epoch: 14\tVal Loss: 0.0045431\tVal ACC:0.8399\n",
      "Train Epoch: 15 60000/60000\tLoss: 0.00414374\tAcc: 0.85595\n",
      "\n",
      "Val Epoch: 15\tVal Loss: 0.00445803\tVal ACC:0.8432\n",
      "Train Epoch: 16 60000/60000\tLoss: 0.00408687\tAcc: 0.857967\n",
      "\n",
      "Val Epoch: 16\tVal Loss: 0.00441305\tVal ACC:0.8449\n",
      "Train Epoch: 17 60000/60000\tLoss: 0.00403093\tAcc: 0.859317\n",
      "\n",
      "Val Epoch: 17\tVal Loss: 0.00434852\tVal ACC:0.8446\n",
      "Train Epoch: 18 60000/60000\tLoss: 0.00398446\tAcc: 0.860583\n",
      "\n",
      "Val Epoch: 18\tVal Loss: 0.0043416\tVal ACC:0.8466\n",
      "Train Epoch: 19 60000/60000\tLoss: 0.00394115\tAcc: 0.862383\n",
      "\n",
      "Val Epoch: 19\tVal Loss: 0.00436881\tVal ACC:0.8476\n",
      "Train Epoch: 20 60000/60000\tLoss: 0.0038795\tAcc: 0.8649\n",
      "\n",
      "***** TESTING on TEST IMAGE 0 *****\n",
      "GroundTruth: 2, Prediction: 2\n",
      "[ Variable[CUDALongType]{} ]\n",
      "Output Probabilities\n",
      "Class: 0 0.00672281\n",
      "Class: 1 0.00144113\n",
      "Class: 2 0.460948\n",
      "Class: 3 0.0228227\n",
      "Class: 4 0.0884988\n",
      "Class: 5 0.000550125\n",
      "Class: 6 0.396917\n",
      "Class: 7 7.34538e-09\n",
      "Class: 8 0.0220995\n",
      "Class: 9 4.45121e-07\n",
      "Outputs saved, Please checkout the output images\n",
      "***** TESTING on TEST IMAGE 1 *****\n",
      "GroundTruth: 3, Prediction: 3\n",
      "[ Variable[CUDALongType]{} ]\n",
      "Output Probabilities\n",
      "Class: 0 0.000209452\n",
      "Class: 1 3.19239e-05\n",
      "Class: 2 0.000433445\n",
      "Class: 3 0.996865\n",
      "Class: 4 0.00209711\n",
      "Class: 5 1.49309e-11\n",
      "Class: 6 0.000339273\n",
      "Class: 7 4.92747e-11\n",
      "Class: 8 2.29207e-05\n",
      "Class: 9 1.43458e-11\n",
      "Outputs saved, Please checkout the output images\n",
      "***** TESTING on TEST IMAGE 2 *****\n",
      "GroundTruth: 2, Prediction: 2\n",
      "[ Variable[CUDALongType]{} ]\n",
      "Output Probabilities\n",
      "Class: 0 0.000504171\n",
      "Class: 1 0.000148144\n",
      "Class: 2 0.939217\n",
      "Class: 3 0.000312431\n",
      "Class: 4 0.0260935\n",
      "Class: 5 4.38722e-09\n",
      "Class: 6 0.0335889\n",
      "Class: 7 6.91261e-13\n",
      "Class: 8 0.000135981\n",
      "Class: 9 8.01626e-12\n",
      "Outputs saved, Please checkout the output images\n",
      "Val Epoch: 20\tVal Loss: 0.00420176\tVal ACC:0.8501\n"
     ]
    }
   ],
   "source": [
    "!./ffnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_iPfitfe9M8P"
   },
   "source": [
    "## <font style=\"color:blue\">Plot Loss and Accuracy Curves using Matplotlib</font>\n",
    "We will be using the matplotlib library to plot the accuracy and loss curves for visualizing how the loss and acuracy changed while training.\n",
    "\n",
    "We had saved the loss and accuracy for training and test data while training for each epoch. We just load the data from those files and put them in a list and finally plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzHKqCs29M8Q"
   },
   "outputs": [],
   "source": [
    "with open(\"loss_acc_train.txt\",'r') as train_file:\n",
    "  train_data = train_file.readlines()\n",
    "with open(\"loss_acc_test.txt\",'r') as test_file:\n",
    "  test_data = test_file.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ce_5SUiW9M8U"
   },
   "outputs": [],
   "source": [
    "train_loss_array = []\n",
    "train_acc_array = []\n",
    "for item in train_data:\n",
    "  loss,acc = item.strip().split(',')\n",
    "  train_loss_array.append(float(loss))\n",
    "  train_acc_array.append(float(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhOjg4aP9M8Y"
   },
   "outputs": [],
   "source": [
    "test_loss_array = []\n",
    "test_acc_array = []\n",
    "for item in test_data:\n",
    "  loss,acc = item.strip().split(',')\n",
    "  test_loss_array.append(float(loss))\n",
    "  test_acc_array.append(float(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rSy1bVLO9M8a",
    "outputId": "af162cfe-5132-4693-a35b-fc6dc71083f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.015568, 0.007957, 0.006559, 0.00584, 0.005399, 0.005109, 0.004898, 0.004743, 0.00462, 0.004512, 0.004435, 0.004349, 0.004274, 0.004211, 0.004144, 0.004087, 0.004031, 0.003984, 0.003941, 0.003879]\n"
     ]
    }
   ],
   "source": [
    "print(train_loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFlOWFXi9M8d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "g2UIfJ7H9M8h",
    "outputId": "3788d24b-a0b2-4231-8d28-1e50c6f71209"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAJARCSmFAAiIjGlABARian/DzLrCTU6m33TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_array,'b')\n",
    "plt.plot(test_loss_array,'r')\n",
    "plt.title(\"Loss Curves\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "lnqFl5WN9M8o",
    "outputId": "b002fd1c-30ff-4e56-acef-e44c5ea1abd5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dfZyUdb3/8ddH7u/k/k7uQVBQk2wD\nbzodO4miWVhZB2/Keyszj5YllpkHK+38qlOnOHbQA96LZidbC39ox+x0EpSlUAGFXdaERYTlVkAU\nWD7nj+81zLWzs+zAzs7sXvN+Ph7XY2au65qZzw7Le777vT5zjbk7IiKSXEcUuwAREWlZCnoRkYRT\n0IuIJJyCXkQk4RT0IiIJp6AXEUk4Bb2ISMIp6KWgzOw5M9tqZp2KXUtLseA6M1tmZrvMrMbMfmlm\nJxS7NilNCnopGDMbCfwd4MAnCvzc7Qv4dD8F/gm4DugDjAOeAD52qA9U4LoloRT0UkifBxYB9wKX\nxDeYWRcz+5GZvWFm283sf82sS7TtQ2b2vJltM7O1ZnZptP45M7sy9hiXmtn/xm67mX3ZzCqBymjd\nT6PHeNvMlpjZ38X2b2dm3zSz1Wa2I9o+zMxmmdmPMuotN7MbMn9AMxsLfBm4wN2fdff33P0dd3/I\n3e88nLrN7C4z+2HG8/zGzL4aXT/KzH5lZrVm9rqZXRfbb5KZVUQ/7wYz+3ET/0aSQAp6KaTPAw9F\ny1lmNjC27YfAB4BTCaPgbwD7zWwE8BTwM6A/MBFYegjPeR4wGZgQ3V4cPUYf4GHgl2bWOdr2VeAC\n4BzgSOBy4B3gPuACMzsCwMz6AWdE98/0UaDG3V88hBqbqvsR4B/NzKLn7w2cCcyLanoSeAkYEj3/\n9WZ2VvQ4PwV+6u5HAmOAx5pZl7RBCnopCDP7EDACeMzdlwCrgQujbUcQQvWf3H2du9e5+/Pu/l60\nz+/d/RF33+vum939UIL+Dnff4u67Adz9wegx9rn7j4BOwDHRvlcCt7j7Sg9eivZ9EdhOCFGA6cBz\n7r4hy/P1BdYfQn251P0nwnRX6q+P84GF7v4m8EGgv7vPdPc97l4N3B3VCLAXONrM+rn7TndflIfa\npI1R0EuhXAI87e6botsPk56+6Qd0JoR/pmGNrM/V2vgNM7vRzF6Npoe2AT2j52/que4DLo6uXww8\n0Mh+m4HBzag35UDdHs48OI/w1waEN7+HousjgKOiaa1t0c/0TSD119IVhGMEr5nZYjM7Nw+1SRuj\nAz3S4qK59s8C7czsrWh1J6CXmZ0IvAK8S5haeCnj7muBSY089C6ga+z2oCz7HDg9azQf/w3CyHy5\nu+83s62AxZ5rDLAsy+M8CCyL6h1POLiazX8Ds8yszN0r8lF35BHgaTO7kzCl88lYza+7+9hsT+Tu\nlaSnnT4FPG5mfd19VyO1SQJpRC+FcB5QR5hvnhgt4wlTEp939/3AHODH0YHFdmZ2StSC+RBwhpl9\n1szam1lfM5sYPe5S4FNm1tXMjiaMXg+mB7APqAXam9mthLn4lHuA281sbNQi+T4z6wvg7jWE+f0H\ngF+lpoIyRcH678AjZna6mXU0s85mNt3MZhxm3bj7X4FNUY0L3H1btOlFYIeZ3RQd0G5nZseb2QcB\nzOxiM+sfvcap++xv6vkkWRT0UgiXAHPdfY27v5VagJ8DF0UthDcSRvaLgS3AD4Aj3H0N4eDo16L1\nS4ETo8f9V2APsIEwtfIQB7cA+P/AKuANwl8R8amdHxMOVj4NvA38J9Altv0+4AQan7ZJuS762WYR\nwnU1YQT+5GHWnfIwGQeB3b0OOJfw5vk66TeDntEuU4HlZraTcGB2emNvUpJcpi8eEcmNmX2YMIUz\nwvUfR9oQjehFcmBmHQgfgrpHIS9tjYJepAlmNp4wBTMY+EmRyxE5ZJq6ERFJOI3oRUQSrtX10ffr\n189HjhxZ7DJERNqUJUuWbHL3/tm2tbqgHzlyJBUVjX3OREREsjGzNxrbpqkbEZGEU9CLiCScgl5E\nJOEU9CIiCaegFxFJOAW9iEjCKehFRBKu1fXRi4gk3d69UFsLGzbAW2+Fyw0boHdvuPrq/D+fgl5E\nJA/eey8d3plLPMw3bIDNm7M/ximnKOhFRFrM/v2wYwds2wZbt4Yldb2xy/j1d9/N/rjdu8PAgWE5\n9lj4+79P304tgwaFy27dWuZnU9CLSJviHkbPO3bAzp1hiV/fuRN27Tr49Wzr3nnn4M9rBr16hemV\n1OXgwfVv9+3bMLy7dj344xaCgl5ECsY9hPLmzbBlS8PL7dvrB3fmZep6XV3uz9m1axhVd+8eRsyp\n6wMHNlzfo0cI7NQSD/YePeCINtq+oqAXkcO2ezesXx/moN96K8xRNxbiqct9+xp/vK5dQ6CmQrd7\n9zBKHjkyHcqZ2+PXu3UL11PB3bVr2w3nfFLQi0g9+/eHUE4FeDzIM9e9/Xb2x+jaFfr0CSHdpw8c\nd1z6dmpd5mWfPtChQ2F/1lKRU9Cb2VTCN8i3I3xn5p0Z24cTvs2+V7TPDHefb2YjgVeBldGui9z9\ni/kpXURyVVcXwjuzG2TjxuzdIdmmRrp3D3PSgwbBiSfC1Knh+qBB6fX9+4fg7ty58D+jNK7JoDez\ndsAsYApQAyw2s3J3XxHb7RbgMXe/y8wmAPOBkdG21e4+Mb9li0hdHWzalB5tZ7bwxZdNm8JIPVPH\njjBgQPrg4cSJ9YM7dT01ny0tbO/eFvmzJpcR/SSgyt2rAcxsHjANiAe9A0dG13sCb+azSJFS4R4O\nSMbDO3NJjbw3bswe3l27pjs/Ro8OvdmpMM9cevYM3STSQtzDEeTG3oEzl4kT4U9/ynsZuQT9EGBt\n7HYNMDljn9uAp83sK0A34IzYtlFm9lfgbeAWd2/wU5jZ1cDVAMOHD8+5eJG2xj2Mrl9/HaqrG16+\n+WZoHczUoUN6hD1sGHzwg+nb8Va+QYM08m4W99AQv3t3WN55J339YOtS67dtaxjeu3c3fB6z+r2Y\nkyaFywkTWuTHytfB2AuAe939R2Z2CvCAmR0PrAeGu/tmM/sA8ISZHefu9Q7huPtsYDZAWVmZ56km\nkaJ45x3429+yB/nrr4cBXtyAATBqFEyeHEI8FeDxpXdvjbwPyb59ocUn3u7T2PX4uh07Dv85O3cO\nfyKlwnvs2Ox/Rg0cGA5mtC9cL0wuz7QOGBa7PTRaF3cFMBXA3ReaWWegn7tvBN6L1i8xs9XAOEBf\nCittRmo6ZdOm0D6YuoxfT12uWROmVeK6dg1BPno0fOQj4TJ1O9U2mAj794c2nO3bw8g2ddnY9Wzr\n9u4N/ZDt2qWXQ7m9e3cI7MbagSDsn2rz6dMHjjoKjj8+XD/yyPAP1qVLesnldqdOrbqPM5egXwyM\nNbNRhICfDlyYsc8a4KPAvWY2HugM1JpZf2CLu9eZ2WhgLFCdt+pFmmnfPli9GlasgFdfDVMn2cK8\nsd7vzp3D4Kx/f+jXL+RFPMhHjQoj9kSMxt99N7yTrVkDb7zR8PratbBnz8Efo2vX8OmjXr3C6Ld/\n/zDy7dkzLJ06haPM8WX//tzW1dWF4E0FeLb+zb59Q5i34lBuCU0GvbvvM7NrgQWE1sk57r7czGYC\nFe5eDnwNuNvMbiAcmL3U3d3MPgzMNLO9wH7gi+6+pcV+GpFGvPcerFqVDvQVK8KyalUYRKb06ZMO\n7TFjwnRK6nb8MnW9pc5NUnCpFp6amsaDfOPG+vcxC6Ph4cPDQYNPfzq8q/XuHUI7HuipSzXKF4W5\nt64p8bKyMq+o0MyOHJ5du+C11xoG+urV6Q6VI44Io+0JE2D8+HA5YUI44VRiplGg/rlwm1qy9V92\n6QIjRoQgz7wcPhyGDAn9mdIqmNkSdy/Ltk2fjJU2wz3k1tq16SU1Y5C6XlOT3r99exg3Lny4Z/r0\ndKCPG5egD/Ts2wevvAIvvAAvvhiOAjd1Ltxs/Zep20OGpIO8b9+EzDmJgl5ajZ0760/3ZoZ5TU3D\nU8F26hQ6VYYNg3/4hzDdmwr0MWMSNlPgHl6EF15IL0uWpE+72K8fHHNM4+fCTS2J+rNFcqGgl4JK\njcpffbXhEh+NQ5hiGTIkhPgHPgCf/GQ61IcNC4POfv3yNOjcsSPM8UCYZx4woPgT8Dt3QkVFOtQX\nLQonmYEwZfL+98OVV8LJJ4eDCaNGaQQuWSnopUXs3x9G4al58nigb4kdju/WLQxATz89zJePGZMO\n8sGDW6DV+N13YeXKMN2xbFl6eeONhvt27ZoO/fgycGDDdf36NV5sXV2YL9+zp+Fl5vXXXksH+7Jl\n6XnzMWNCb2Yq1E88Mfw5I5IDBb00265dsHhxGHAuWxbC/LXX6n+RQ9++YTrl/PNDoKeWoUNbqNMt\n1TcZD/Nly6CyMn3Grg4dQhGnnQZf+EI4xWL79umzfcWXmhr4y1/C9cZ6Lfv2DY+ZGejZzlNwML16\nhU9KTpsWgn3SpPBGInKYFPRySNzDpzsXLgzL88/Dyy+ns3PYsJCdV11VP9D792/BojZuhKVLw7Js\nWRitv/pq+lwCZnD00aHJ/TOfCZfHHx8m9A91Et89/TH3zDeDjRvDC9GhQ5haOZzLkSNDXSXW5y0t\nS0EvB7V7d5gmToX6woXpdupu3cJg86ab4NRTw+Czb98WLKauDqqq0qG+dCm89FJ63hrCnwjHHw9n\nnJEO9PHj8/d9bmbprx869tj8PKZIC1PQywHuocMlHupLl6ZnKo4+Gs46K3TjnXJKyNAWO13Hrl1h\nZB4P9VdeSc8HtW8fplqmTAln/Js4Mcxb9+nTQgWJtF0KeuHll+Ghh+DRR9PHJLt2DR92vPHGEOon\nnxyOOebdjh1h3jy1pMK9sjK880CYs544McwHpUJ9/HgdjBTJkYK+RK1ZAw8/HAJ+2bJwPqizzgrB\nfuqpcMIJeexB37kzTLnEAz11e8OG+vuOGhWC/MIL06E+fLjaBkWaQUFfQrZsgV/+MoR76rsNTjkF\nfv5z+Oxnm3nA9N13w4ljVq1qGOqZp3McPDjMA33sY+HAY2oZM6b4vesiCaSgT7jdu+HJJ0O4P/VU\n6PY79li4/fYwaB49+hAfcMeO+k3xqSb56ur6bYSp83GffXYI9VSYH320PpkpUmAK+gSqq4Nnnw3h\n/l//FbL5qKPguuvgoovCbEiTMyGbNtUP8tRl/OOrHTqEE8ekplrGjw+3jz46nApWRFoFBX2CLF0K\n990H8+aF2ZIjjwwfULr44nDqk3btstzJPXywaOHC9CeeVqwIQZ8S//hq6pSPqY+xFvBbckTk8Oh/\naQK89BJ8+9thiqZjxzD1fdFF4bLBWRpTH2NNfeJp0aJw8hmAHj3gfe+D885Ln793/PjwKSh9gEek\nzVLQt2GvvQbf+Q489lj4TofvfheuuSZ8lgeIRuvV6VBfuLD+x1iPOSa8G6Qa4ydMaGTYLyJtmYK+\nDXr9dZg5E+6/P3w3xLe+BV/7GvTu9E76Y6ypJfUx1u7dw8mwbr45hPrkyS38MVYRaS0U9G3IunVh\n1H7PPWHgff31MOMb++m/4o9w3Rz41a9Cmw2Eg6Jnn50erR93nEbrIiVKQd8G1NbCnXfCv/97OB3B\nVVfBrZe8waAF98HJc8O3CvXsCZdcAueeW4CTzohIW5JT0JvZVOCnhC8Hv8fd78zYPhy4D+gV7TPD\n3edH224GrgDqgOvcfUH+yk+2bdvghz+En/wkDNSvuHA33/3Arxnw2zlwyrNhp49+FL73vfCtHF26\nFLdgEWmVmgx6M2sHzAKmADXAYjMrd/cVsd1uAR5z97vMbAIwHxgZXZ8OHAccBfzezMa5e12+f5Ak\n2bkTfvrTEPLbtjnfPGMxN/adS+8nH4EHt4fTBNx2WxjBjxhR7HJFpJXLZUQ/Cahy92oAM5sHTAPi\nQe9A6hMyPYE3o+vTgHnu/h7wuplVRY+3MA+1J87u3XDXXXDHHXDEpg38aMKDXNB3Ll1+vzyM1s8/\nHy67LDTFq91RRHKUS9APAdbGbtcAkzP2uQ142sy+AnQDzojdd1HGfYccVqUJV1kJ50zZy/g3nuI3\n/edwcrvfccSKfWG+/abZ4WQ0PXsWu0wRaYPydTD2AuBed/+RmZ0CPGBmx+d6ZzO7GrgaYPjw4Xkq\nqe1YuRK+d+rveG7bFxlCDRwxEL56Qxi9jx9f7PJEpI3LJejXAcNit4dG6+KuAKYCuPtCM+sM9Mvx\nvrj7bGA2QFlZmedafBKsenEbS0+/nvt338e7Y0+AH84KbZF5O0ewiJS6XCZ6FwNjzWyUmXUkHFwt\nz9hnDfBRADMbD3QGaqP9pptZJzMbBYwFXsxX8W3dml/Mp8cpx/Hp3Q9S+4Vb6LysAj7xCYW8iORV\nkyN6d99nZtcCCwitk3PcfbmZzQQq3L0c+Bpwt5ndQDgwe6m7O7DczB4jHLjdB3xZHTfAtm1su+wG\nhj9xL6+2P553Hytn1Kc/UOyqRCShzL11zZSUlZV5RUVFsctoOU89xd5Lr8I2vsXPu8/gnOe/zbgT\n9JV4ItI8ZrbE3cuybVOPXqFs2waXXw7nnEPV5l58vN8izlnyXYW8iLQ4nQKhEJ56Cq66Cl+/np90\nuZmf9f4OC57rxNixxS5MREqBRvQtaft2uOIKOOccdnfqyZk9FvHjvt/n6T8q5EWkcBT0LWXBAjj+\neLj3Xt66dAZjti5h5ZEf5LnnwjftiYgUioI+37ZvhyuvhKlToUcPXp2zkAm/uYOOR3bmj38M374n\nIlJImqPPp2eeCQdc33wTbrqJinNvY8rHO9OzJzz3HIwcWewCRaQUKejzZcmSMIofNw6ef54XbTJn\nngl9+sAf/qCTTIpI8WjqJh/27YOrr4YBA2DhQl5gMlOmhO/+eO45hbyIFJdG9Pkwaxb85S/w6KMs\nfLUXZ50VMv8Pf4Bhw5q+u4hIS9KIvrnWroVbboGzz+bPR32GM8+EQYPCSF4hLyKtgUb0zfWVr0Bd\nHbW3zeLsM4yjjoJnn4UhOuu+iLQSCvrmeOIJ+M1v4Ac/4I55o9i1C8rLFfIi0roo6A/Xjh1w7bVw\nwgmsn34Ddx0DF18MxxxT7MJEROpT0B+ub3879Ms//jg/+HEH9u4Nq0REWhsdjD0cFRXws5/Bl77E\nm8NP5he/gM99Tqc2EJHWSUF/qPbtgy98IfRPfv/73HlnWKXRvIi0Vpq6OVQ/+1nomX/sMdbt7Mns\n2XDppTB6dLELExHJTkF/KNasCUP3c86B88/njtBZyS23FLswEZHGaeomV+6hy2b/fpg1i7U1xt13\nw2WX6WRlItK6aUSfqyeegCefhH/5Fxg5kjuuCdn/rW8VuzARkYPLaURvZlPNbKWZVZnZjCzb/9XM\nlkbLKjPbFttWF9tWns/iC+btt8MnYE88Ea6/njVr4J57whmJdcIyEWntmhzRm1k7YBYwBagBFptZ\nubuvSO3j7jfE9v8K8P7YQ+x294n5K7kIUj3zv/oVdOjA978fVn/zm8UtS0QkF7mM6CcBVe5e7e57\ngHnAtIPsfwHwSD6KaxUWLw6dNtdcA5Mn88YbMGdO+BKp4cOLXZyISNNyCfohwNrY7ZpoXQNmNgIY\nBTwbW93ZzCrMbJGZndfI/a6O9qmora3NsfQCSJ1nftAg+N73gHBhptG8iLQd+T4YOx143N3rYutG\nuPs6MxsNPGtmr7j76vid3H02MBugrKzM81zT4fu3f4OlS+GXv4SePXn9dZg7N3xeaujQYhcnIpKb\nXEb064D4mdWHRuuymU7GtI27r4suq4HnqD9/33q98UaYm//Yx+DTnwbCaL5dO7j55iLXJiJyCHIJ\n+sXAWDMbZWYdCWHeoHvGzI4FegMLY+t6m1mn6Ho/4DRgReZ9W51UzzzAz38OZlRXw733hpkcnYZY\nRNqSJqdu3H2fmV0LLADaAXPcfbmZzQQq3D0V+tOBee4en3oZD/yHme0nvKncGe/WabV+/Wv47W/h\nhz888Gmo734XOnSAGQ2aS0VEWjern8vFV1ZW5hUVFcUrYPt2mDAB+vcPZ6ls356qKjj22DDI/8lP\nileaiEhjzGyJu5dl26ZPxma65RZYvz6M6tuHlyc1mr/ppiLXJiJyGHSum7gXX4RZs+DLX4ZJkwCo\nrIQHHoAvfQkGDy5yfSIih0FBn1JXF/omBw8OQ/jI7bdDp04azYtI26Wpm5Rnnw098/ffDz17ArBy\nJTz0ENxwAwwcWOT6REQOk0b0KXPmQK9e8JnPHFh1++3QuTN84xtFrEtEpJkU9ABbt4aDrxddFJId\neO01eOSRMF0/YECR6xMRaQYFPcC8efDee+FbRCIzZ0KXLvD1rxexLhGRPFDQQziBzQknwEknAbBi\nRcj+a68N7fQiIm2Zgn7ZsnAq4ssuC6elJIzmu3WDG28scm0iInmgoJ87N3ww6uKLAVi+HB57LHyh\nVL9+Ra5NRCQPSjvo9+6FBx+Ej3/8wBzNP/8zdO8OX/takWsTEcmT0g76+fNh48YDB2FfeSWcev66\n66Bv3yLXJiKSJ6Ud9HPmhG+POvtsIIzmjzwSvvrVItclIpJHpRv0GzbA734Hn/sctG/P5s3hu7+v\nuQb69Cl2cSIi+VO6Qf/gg+H8NtG0zapVYfVppxWxJhGRFlCaQe8epm0mT4bx4wGoqgqbxo4tYl0i\nIi2gNIN+8eLwqajLLz+wqrISjjjiwBdKiYgkRmkG/dy54fwG//iPB1ZVVcHw4eGUxCIiSVJ6Qb97\ndzhb2ac+deB0xBCCXtM2IpJEpRf0TzwRvhc2dgIz9zB1c/TRRaxLRKSF5BT0ZjbVzFaaWZWZzciy\n/V/NbGm0rDKzbbFtl5hZZbRcks/iD8vcuTBiBHzkIwdWbdkC27ZpRC8iydTkN0yZWTtgFjAFqAEW\nm1m5u69I7ePuN8T2/wrw/uh6H+A7QBngwJLovlvz+lPkas0a+P3v4dZbw5HXSGVluNSIXkSSKJcR\n/SSgyt2r3X0PMA+YdpD9LwAeia6fBTzj7luicH8GmNqcgpvlvvvCPM0l9f+wUGuliCRZLkE/BFgb\nu10TrWvAzEYAo4BnD+W+Zna1mVWYWUVtbW0udR+6/fvh3nvDlM2oUfU2pVorM1aLiCRCvg/GTgce\nd/e6Q7mTu8929zJ3L+vfUt/08ac/QXV1vd75FLVWikiS5RL064BhsdtDo3XZTCc9bXOo921Zc+aE\nM5Z96lMNNqnjRkSSLJegXwyMNbNRZtaREOblmTuZ2bFAb2BhbPUC4Ewz621mvYEzo3WFtWMHPP54\n+IBU164NNquHXkSSrMmuG3ffZ2bXEgK6HTDH3Zeb2Uygwt1ToT8dmOfuHrvvFjO7nfBmATDT3bfk\n90fIwWOPwTvv1OudT9m8GbZu1YheRJKryaAHcPf5wPyMdbdm3L6tkfvOAeYcZn35MXcuHHssnHxy\ng03quBGRpEv+J2NXroQ//7nel3/HqYdeRJIu+UF/773Qrl34gpEsqqpC/o8eXdiyREQKJdlBX1cH\n998PU6fC4MFZd6msVGuliCRbsoP+6afhzTez9s6nVFVp2kZEki3ZQT9nDvTrB+ee2+guaq0UkaRL\nbtBv3gzl5XDRRdCxY9ZdtmwJi0b0IpJkyQ36hx+GPXuy9s6nqLVSREpBcoN+7lw46SQ48cRGd1Fr\npYiUgmQG/dKl8Ne/HnQ0D2qtFJHSkMygnzs3zMtfeOFBd6ushGHDoHPnAtUlIlIEyQv6PXvgoYdg\n2jTo0+egu6rjRkRKQfKC/sknQ8fNQXrnU3R6YhEpBckL+rlzYcgQmDLloLulWis1oheRpEtW0L/5\nJjz1FHz+8+H8NgeRaq3UiF5Eki5ZQf/AA+G7YS+9tMld1UMvIqUiOUHvHqZtPvQhGDeuyd0rK9Va\nKSKlITlBX10Na9Y02TufUlWl1koRKQ05fcNUmzBmDKxf3+h5bTKp40ZESkVyRvQAPXtCly457aoe\nehEpFckK+hxt3Rpa7TWiF5FSkFPQm9lUM1tpZlVmNqORfT5rZivMbLmZPRxbX2dmS6OlPF+FN4da\nK0WklDQ5R29m7YBZwBSgBlhsZuXuviK2z1jgZuA0d99qZgNiD7Hb3Sfmue5mUWuliJSSXEb0k4Aq\nd6929z3APGBaxj5XAbPcfSuAu2/Mb5n5lTo9sVorRaQU5BL0Q4C1sds10bq4ccA4M/uzmS0ys6mx\nbZ3NrCJaf162JzCzq6N9Kmpraw/pBzgcqdbKHI/bioi0aflqr2wPjAVOB4YC/2NmJ7j7NmCEu68z\ns9HAs2b2iruvjt/Z3WcDswHKyso8TzU1Sq2VIlJKchnRrwOGxW4PjdbF1QDl7r7X3V8HVhGCH3df\nF11WA88B729mzc2m1koRKSW5BP1iYKyZjTKzjsB0ILN75gnCaB4z60eYyqk2s95m1im2/jRgBUW0\nbRts2qQRvYiUjianbtx9n5ldCywA2gFz3H25mc0EKty9PNp2ppmtAOqAr7v7ZjM7FfgPM9tPeFO5\nM96tUwzquBGRUpPTHL27zwfmZ6y7NXbdga9GS3yf54ETml9m/ugLwUWk1JTcJ2NTI/oxY4pbh4hI\noZRc0FdWwtChaq0UkdJRckGvjhsRKTUlGfSanxeRUlJSQb99O9TWakQvIqWlpIJeZ60UkVJUUkGv\n1koRKUUlFfRqrRSRUlRSQV9ZCUOGQNeuxa5ERKRwSiro1VopIqWopIJepycWkVJUMkGv1koRKVUl\nE/RqrRSRUlVyQa8RvYiUmpIJ+lQPvVorRaTUlEzQV1WptVJESlPJBL06bkSkVJVM0KuHXkRKVUkE\n/dtvw8aNGtGLSGkqiaBXx42IlLKcgt7MpprZSjOrMrMZjezzWTNbYWbLzezh2PpLzKwyWi7JV+GH\nQj30IlLK2je1g5m1A2YBU4AaYLGZlbv7itg+Y4GbgdPcfauZDYjW9wG+A5QBDiyJ7rs1/z9K49Ra\nKSKlLJcR/SSgyt2r3X0PMA+YlrHPVcCsVIC7+8Zo/VnAM+6+Jdr2DDA1P6XnrqoKjjoKunUr9DOL\niBRfLkE/BFgbu10TrYsbB4wzsz+b2SIzm3oI98XMrjazCjOrqK2tzb36HKm1UkRKWb4OxrYHxgKn\nAxcAd5tZr1zv7O6z3b3M3faZFl4AAAjzSURBVMv69++fp5LS1FopIqUsl6BfBwyL3R4arYurAcrd\nfa+7vw6sIgR/LvdtUW+/DRs2aEQvIqUrl6BfDIw1s1Fm1hGYDpRn7PMEYTSPmfUjTOVUAwuAM82s\nt5n1Bs6M1hXM6tXhUiN6ESlVTXbduPs+M7uWENDtgDnuvtzMZgIV7l5OOtBXAHXA1919M4CZ3U54\nswCY6e5bWuIHaYy+EFxESl2TQQ/g7vOB+Rnrbo1dd+Cr0ZJ53znAnOaVefjUQy8ipS7xn4ytrITB\ng9VaKSKlK/FBr44bESl1iQ969dCLSKlLdNDv2BFaKzWiF5FSluigT7VWakQvIqUs0UGfaq3UiF5E\nSlmigz7VWqmzVopIKUt00KdaK7t3L3YlIiLFk+igr6rS/LyISKKDvrJS8/MiIokN+p074a23NKIX\nEUls0OscNyIiQeKDXlM3IlLqEhv0+kJwEZEgsUFfVQWDBkGPHsWuRESkuBIb9DqZmYhIkNig1+mJ\nRUSCRAb9rl2wfr1G9CIikNCgV8eNiEhaTkFvZlPNbKWZVZnZjCzbLzWzWjNbGi1XxrbVxdaX57P4\nxqiHXkQkrckvBzezdsAsYApQAyw2s3J3X5Gx66Pufm2Wh9jt7hObX2ruUq2VCnoRkdxG9JOAKnev\ndvc9wDxgWsuW1TxVVTBwoForRUQgt6AfAqyN3a6J1mX6tJm9bGaPm9mw2PrOZlZhZovM7LxsT2Bm\nV0f7VNTW1uZefSN0MjMRkbR8HYx9Ehjp7u8DngHui20b4e5lwIXAT8yswWdV3X22u5e5e1n//v2b\nXYxOTywikpZL0K8D4iP0odG6A9x9s7u/F928B/hAbNu66LIaeA54fzPqbdKuXfDmmxrRi4ik5BL0\ni4GxZjbKzDoC04F63TNmNjh28xPAq9H63mbWKbreDzgNyDyIm1f6QnARkfqa7Lpx931mdi2wAGgH\nzHH35WY2E6hw93LgOjP7BLAP2AJcGt19PPAfZraf8KZyZ5ZunbxSx42ISH1NBj2Au88H5mesuzV2\n/Wbg5iz3ex44oZk1HhL10IuI1Je4T8ZWVsKAAXDkkcWuRESkdUhc0OtkZiIi9SUu6HV6YhGR+hIV\n9GqtFBFpKFFBX10dLjWiFxFJS1TQp1orNaIXEUlLVNCrtVJEpKFEBb1aK0VEGkpU0OtkZiIiDSUq\n6HV6YhGRhhIT9O+8A+vWaUQvIpIpMUG/axdccAFMnlzsSkREWpecTmrWFvTvDw8/XOwqRERan8SM\n6EVEJDsFvYhIwinoRUQSTkEvIpJwCnoRkYRT0IuIJJyCXkQk4RT0IiIJZ+5e7BrqMbNa4I1mPEQ/\nYFOeymkJqq95VF/zqL7mac31jXD3/tk2tLqgby4zq3D3smLX0RjV1zyqr3lUX/O09voao6kbEZGE\nU9CLiCRcEoN+drELaILqax7V1zyqr3lae31ZJW6OXkRE6kviiF5ERGIU9CIiCdcmg97MpprZSjOr\nMrMZWbZ3MrNHo+0vmNnIAtY2zMz+YGYrzGy5mf1Tln1ON7PtZrY0Wm4tVH2xGv5mZq9Ez1+RZbuZ\n2b9Fr+HLZnZSAWs7JvbaLDWzt83s+ox9CvoamtkcM9toZsti6/qY2TNmVhld9m7kvpdE+1Sa2SUF\nrO//mdlr0b/fr82sVyP3PejvQgvWd5uZrYv9G57TyH0P+v+9Bet7NFbb38xsaSP3bfHXr9ncvU0t\nQDtgNTAa6Ai8BEzI2Oca4BfR9enAowWsbzBwUnS9B7AqS32nA78t8uv4N6DfQbafAzwFGHAy8EIR\n/73fInwYpGivIfBh4CRgWWzdvwAzouszgB9kuV8foDq67B1d712g+s4E2kfXf5Ctvlx+F1qwvtuA\nG3P49z/o//eWqi9j+4+AW4v1+jV3aYsj+klAlbtXu/seYB4wLWOfacB90fXHgY+amRWiOHdf7+5/\nia7vAF4FhhTiufNsGnC/B4uAXmY2uAh1fBRY7e7N+bR0s7n7/wBbMlbHf8/uA87LctezgGfcfYu7\nbwWeAaYWoj53f9rd90U3FwFD8/28uWrk9ctFLv/fm+1g9UXZ8VngkXw/b6G0xaAfAqyN3a6hYZAe\n2Cf6Rd8O9C1IdTHRlNH7gReybD7FzF4ys6fM7LiCFhY48LSZLTGzq7Nsz+V1LoTpNP4frNiv4UB3\nXx9dfwsYmGWf1vI6Xk74Cy2bpn4XWtK10dTSnEamvlrD6/d3wAZ3r2xkezFfv5y0xaBvE8ysO/Ar\n4Hp3fztj818IUxEnAj8Dnih0fcCH3P0k4Gzgy2b24SLUcFBm1hH4BPDLLJtbw2t4gIe/4Vtlr7KZ\nfQvYBzzUyC7F+l24CxgDTATWE6ZHWqMLOPhovtX/X2qLQb8OGBa7PTRal3UfM2sP9AQ2F6S68Jwd\nCCH/kLv/V+Z2d3/b3XdG1+cDHcysX6Hqi553XXS5Efg14U/kuFxe55Z2NvAXd9+QuaE1vIbAhtR0\nVnS5Mcs+RX0dzexS4FzgoujNqIEcfhdahLtvcPc6d98P3N3I8xb79WsPfAp4tLF9ivX6HYq2GPSL\ngbFmNioa8U0HyjP2KQdS3Q3nA8829kueb9F83n8Cr7r7jxvZZ1DqmIGZTSL8OxTyjaibmfVIXScc\ntFuWsVs58Pmo++ZkYHtsmqJQGh1JFfs1jMR/zy4BfpNlnwXAmWbWO5qaODNa1+LMbCrwDeAT7v5O\nI/vk8rvQUvXFj/l8spHnzeX/e0s6A3jN3WuybSzm63dIin00+HAWQkfIKsLR+G9F62YSfqEBOhP+\n3K8CXgRGF7C2DxH+hH8ZWBot5wBfBL4Y7XMtsJzQQbAIOLXAr9/o6LlfiupIvYbxGg2YFb3GrwBl\nBa6xGyG4e8bWFe01JLzhrAf2EuaJryAc9/lvoBL4PdAn2rcMuCd238uj38Uq4LIC1ldFmN9O/R6m\nOtGOAuYf7HehQPU9EP1uvUwI78GZ9UW3G/x/L0R90fp7U79zsX0L/vo1d9EpEEREEq4tTt2IiMgh\nUNCLiCScgl5EJOEU9CIiCaegFxFJOAW9iEjCKehFRBLu/wDxx/YbMiY1qQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_acc_array,'b')\n",
    "plt.plot(test_acc_array,'r')\n",
    "plt.title(\"Accuracy Curves\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMRxB-Cf9M8t"
   },
   "source": [
    "References:\n",
    "- https://pytorch.org/tutorials/advanced/cpp_frontend.html\n",
    "- https://github.com/pytorch/examples/blob/master/cpp/custom-dataset/custom-dataset.cpp"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FeedForward_Neural_Network.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
